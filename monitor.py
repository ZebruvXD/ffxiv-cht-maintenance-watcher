import requests
import re
import os
import time
from playwright.sync_api import sync_playwright

# --- é…ç½®å€ ---
DISCORD_WEBHOOK_URL = os.environ["DISCORD_WEBHOOK"]
LAST_NEWS_FILE = "last_news_title.txt"

def send_to_discord(title, link, text_content):
    """å°‡æ–‡å­—å…¬å‘Šç™¼é€åˆ° Discord"""
    # Discord Embed çš„å…§å®¹ä¸Šé™ç‚º 4096 å­—ï¼Œä¿éšªèµ·è¦‹æˆªæ–·åœ¨ 3000 å­—
    if len(text_content) > 3000:
        text_content = text_content[:3000] + "\n\n...(å…§å®¹éé•·ï¼Œè«‹é»æ“Šé€£çµæŸ¥çœ‹å…¨æ–‡)"

    payload = {
        "username": "FFXIV å…¬å‘Šå°å¹«æ‰‹",
        "embeds": [{
            "title": title,
            "url": link,
            "description": text_content,
            "color": 3447003,  # è—è‰²
            "footer": {"text": f"æ“·å–æ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}"}
        }]
    }

    res = requests.post(DISCORD_WEBHOOK_URL, json=payload)
    if res.status_code in [200, 204]:
        print("âœ… å…¬å‘Šå·²æˆåŠŸç™¼é€åˆ° Discord")
    else:
        print(f"âŒ ç™¼é€å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {res.status_code}")

def run_scraper():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        # 1. åˆ—è¡¨é æŠ“é€£çµ
        try:
            page.goto("https://www.ffxiv.com.tw/web/news/news_list.aspx?category=3", timeout=60000)
            page.wait_for_selector(".news_list .item")

            first_item = page.query_selector(".news_list .item")
            title = first_item.query_selector(".title a").inner_text().strip()
            link = "https://www.ffxiv.com.tw" + first_item.query_selector(".title a").get_attribute("href")

            # æª¢æŸ¥æ˜¯å¦å·²ç™¼é€é
            if os.path.exists(LAST_NEWS_FILE):
                with open(LAST_NEWS_FILE, "r", encoding="utf-8") as f:
                    if f.read().strip() == title:
                        print(f"ğŸ˜´ å·²è™•ç†éæœ€æ–°å…¬å‘Š: {title}")
                        return

            # 2. é€²å…¥å…§æ–‡é æŠ“å– .article
            page.goto(link, timeout=60000)
            page.wait_for_selector(".article")

            # ä½¿ç”¨ inner_text() å¯ä»¥ä¿ç•™å¤§éƒ¨åˆ†çš„æ›è¡Œèˆ‡ç¸®æ’æ’ç‰ˆ
            article_element = page.query_selector(".article")
            raw_text = article_element.inner_text().strip()

            # ç°¡å–®æ¸…ç†ï¼šå°‡ä¸‰å€‹ä»¥ä¸Šçš„é€£çºŒæ›è¡Œç¸®æ¸›ç‚ºå…©å€‹ï¼Œä¿æŒæ®µè½æ„Ÿä½†ä¸æµªè²»ç©ºé–“
            formatted_text = re.sub(r'\n{3,}', '\n\n', raw_text)

            # 3. åŸ·è¡Œç™¼é€
            send_to_discord(title, link, formatted_text)

            # 4. æ›´æ–°ç´€éŒ„
            with open(LAST_NEWS_FILE, "w", encoding="utf-8") as f:
                f.write(title)

        except Exception as e:
            print(f"ç™¼ç”ŸéŒ¯èª¤: {e}")
        finally:
            browser.close()

if __name__ == "__main__":
    run_scraper()